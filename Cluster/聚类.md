# 聚类

## 聚类分析的度量

内部指标：不借助任何外部参考，只用参与聚类的样本评判聚类结果的好坏

外部指标：用事先指定的聚类模型作为参考来评判俱来结果的好坏

a = |SS|：$x_i , y_j$​在C和P中属于相同的簇ܲ

b = |SD|：$ x_i , y_j $ 在C中属于相同的簇ܲ，在P中属于不同的簇ܲ

c = |DS|：$x_i,y_j$​在C中属于不同的簇ܲ，在P中属于相同的簇ܲ

d = |DD|：$x_i,y_y$​​在C和P中属于不同的簇ܲ

### 外部指标

#### Rand统计量

![image-20210805103554003](http://tenjoutena.oss-cn-guangzhou.aliyuncs.com/img/image-20210805103554003.png)

#### F值

![image-20210805103614537](http://tenjoutena.oss-cn-guangzhou.aliyuncs.com/img/image-20210805103614537.png)

#### Jaccard系数

![image-20210805103637052](http://tenjoutena.oss-cn-guangzhou.aliyuncs.com/img/image-20210805103637052.png)

#### FM指数

![image-20210805103654478](http://tenjoutena.oss-cn-guangzhou.aliyuncs.com/img/image-20210805103654478.png)

四个度量指标的值越大，表明聚类结果和参考模型直接的划分结果越吻合，聚类结果就越好

### 内部指标

#### 欧式距离

![image-20210805103736012](http://tenjoutena.oss-cn-guangzhou.aliyuncs.com/img/image-20210805103736012.png)

#### 曼哈顿距离

![image-20210805103754263](http://tenjoutena.oss-cn-guangzhou.aliyuncs.com/img/image-20210805103754263.png)

#### 切比雪夫距离

![image-20210805103818401](http://tenjoutena.oss-cn-guangzhou.aliyuncs.com/img/image-20210805103818401.png)

#### 明可夫斯基距离

![image-20210805103838419](http://tenjoutena.oss-cn-guangzhou.aliyuncs.com/img/image-20210805103838419.png)



## K-means聚类

k-均值算法：

1.   选择 K 个初始质心(K需要用户指定），初始质心随机选择即可，每一个质心为一个类
2.   对剩余的每个样本点，计算它们到各个质心的欧式距离，并将其归入到相互间距离最小的质心所在的簇。计算各个新簇的质心。
3.   在所有样本点都划分完毕后，根据划分情况重新计算各个簇的质心所在位置，然后迭代计算各个样本点到各簇质心的距离，对所有样本点重新进行划分
4.   重复2. 和 3.，直到质心不在发生变化时或者到达最大迭代次数时
     

## 层次聚类

聚合聚类算法：

输入：n个样本组成得样本集合及样本之间的距离

输出：对样本集合的一个层次化聚类

1.   计算n个样本两两之间的欧式距离$\{d_{ij}\}$，记作矩阵$D=[d_{ij_{n\times{n}}}]$
2.   构造n个类，每个类只包括一个样本
3.   合并类间距离最小的两个类，其中最短距离为类间距离，构建一个新类
4.   计算新类与当前各类的距离。若类的个数为1，终止计算，否则回到步3.



## 密度聚类

DBSCAN

![image-20210805153308929](http://tenjoutena.oss-cn-guangzhou.aliyuncs.com/img/image-20210805153308929.png)

![image-20210805153716159](http://tenjoutena.oss-cn-guangzhou.aliyuncs.com/img/image-20210805153716159.png)



## 学习向量量化(Learning Vector Quantization)

LVQ试图找到一组原型向量来刻画聚类结构,但与一般聚类算法不同的是,LVQ假设数据样本带有标记,学习过程利用样本的这些监督信息来辅助聚类

![image-20210806111024600](http://tenjoutena.oss-cn-guangzhou.aliyuncs.com/img/image-20210806111024600.png)

对于样本$x_j$,若最近的原型向量$p_i^*与x_j$的类别标记相同,则令$p_i^*$向$x_j$的方向靠拢,类别不同则远离

在学得一组原型向量$\{p_1, p_2, ...,p_q\}$后,即可实现对样本空间$\varkappa$的簇划分,对任意样本x,它被划入预期距离最近的原型向量所代表的簇中,换言之,每个原型向量$p_i$的距离,即
$$
R_i=\{x\in\varkappa\|\quad||x-p_i||_2 <=||x-p_{i^{'}}||_2,i^{'}\ne i\}
$$
该划分通常称为Voronoi剖分



## 高斯混合聚类

高斯混合聚类采用概率模型来表达聚类原型

![image-20210806112417469](http://tenjoutena.oss-cn-guangzhou.aliyuncs.com/img/image-20210806112417469.png)