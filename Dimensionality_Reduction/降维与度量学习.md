

# 降维与度量学习

## K近邻学习

给定测试样本，基于某种距离度量找出训练集中与其最靠近的k个训练样本，然后基于这k个邻居的信息来进行预测

## 低维嵌入

维数灾难：在高维情形下出现的数据样本稀疏、距离计算困难等问题

### 多维缩放Multiple Dimensional Scaling(MDS)

假定$m$个样本之间的距离在原始控件的距离矩阵为$D$，我们目的是获得降维到$d$​维度的样本矩阵$Z$
$$
D\in{R^{m\times{m}}}→Z\in{R}^{d\times{m}}
$$
第$i$个样本和第$j$个样本在$D$中距离为$dist[i,j]$，在$Z$中为$||Zi-Zj||$​（矩阵第i行减去第j行后的1范数），且$dist[i,j]=||Zi-Zj||$

我们令$B=Z^TZ$，则$b_{ij}=z_i^Tz_j$​ ，从而得到：
$$
dist_{ij}^2=||z_i-z_j||^2=||z_i||^2+||z_j||^2-2z_i^Tz_j=b_{ii}+b_{jj}-2b_{ij}
$$
令样本矩阵Z被中心化

![image-20210803103238690](http://tenjoutena.oss-cn-guangzhou.aliyuncs.com/img/image-20210803103238690.png)

令

![image-20210803103318714](http://tenjoutena.oss-cn-guangzhou.aliyuncs.com/img/image-20210803103318714.png)

可得

![image-20210803103345653](http://tenjoutena.oss-cn-guangzhou.aliyuncs.com/img/image-20210803103345653.png)

对距离矩阵B做特征值分解
$$
B=V\Lambda{V}^T
$$
$\Lambda$为特征值构成的对角矩阵，$V$为特征向量矩阵，假定其中由$d^*$​个非零特征值（从大到小），它们构成的对角矩阵$\Lambda_*$，则Z可以表达为
$$
Z=\Lambda_*^{1/2}V_*\in{R^{d^*\times{m}}}
$$

## 主成分分析法（PCA）

Principal Component Analysis

用途：降维

目标：提取最有价值的信息（基于方差）

### 基变换

基是正交的（内积为0，或直观说相互垂直）

要求：线性无关 

变换：数据与一个基做内积运算，结果作为第一个新的坐标分量，然后与第二个基做内积运算，结果作为第二个新坐标的分量

### 协方差矩阵

希望投影后的投影值尽可能分散

方差
$$
Var(a)=\frac{1}{m}\sum_{i=1}^m(a_i-\mu)^2
$$
协方差（假设均值为0时）以0为中心化
$$
Cov(a,b)=\frac{1}{m}\sum_{i=1}^ma_ib_i
$$
（均值不为0）
$$
Cov(a,b)=\frac{1}{m}\sum_{i=1}^m(a_i-\mu_a)(b_i-\mu_b)
$$

### 中心化数据

$$
\sum_{i=1}^n\frac{x_i}{n}=\bar{x},x_i^{'}=x_i-\bar{x}
$$



### 矩阵对角化

设原始数据矩阵 X 对应的协方差矩阵为 C，而 P 是一组基按行组成的矩阵，设 Y=PX，则 Y 为 X 对 P 做基变换后的数据。设 Y 的协方差矩阵为 D

![image-20210803161728204](http://tenjoutena.oss-cn-guangzhou.aliyuncs.com/img/image-20210803161728204.png)

对协方差矩阵 C 有如下结论

![image-20210803162127563](http://tenjoutena.oss-cn-guangzhou.aliyuncs.com/img/image-20210803162127563.png)

### 求解步骤

![image-20210803162209248](http://tenjoutena.oss-cn-guangzhou.aliyuncs.com/img/image-20210803162209248.png)



## 核化线性降维

### KPCA

非线性降维的一种常用方法，是基于核技巧对线性降维方法进行“核化”。

假设将在高维特征空间中把数据投影到由$W=(\omega_1,\omega_2,...,\omega_d)$确定的超平面上，则对于$\omega_j$,
$$
(\sum_{i=1}^mz_iz_i^T)\omega_j=\lambda_j\omega_j
$$
其中$z_i$是样本点$x_i$在高维特征空间中的像
$$
\omega_j=\frac{1}{\lambda_j}(\sum_{i=1}^mz_iz_i^T)\omega_j=\sum_{i=1}^mz_i\frac{z_i^T\omega_j}{\lambda_j}=\sum_{i=1}^mz_i\alpha_i^j
$$
假定$z_i$是由原始属性空间的样本点$x_i$通过映射$\phi$产生,上两式可变为
$$
(\sum_{i=1}^m\phi(x_i)\phi(x_i)^T)\omega_j=\lambda_j\omega_j
$$

$$
\omega_j=\sum_{i=1}^m\phi(x_i)\alpha_i^j
$$

引入核函数
$$
\kappa(x_i,x_j) = \phi(x_i)^T\phi(x_j)
$$

$$
K\alpha^j=\lambda_j\alpha^j
$$

$K$为$\kappa$对应的核矩阵，$(K)_{ij}=\kappa(x_i,x_j),\alpha=(\alpha_1^j;\alpha_2^j;...;\alpha_m^j)$

对新样本$x$，其投影后的第$j$维坐标为

$z_j=\omega_j^T\phi(x)=\sum_{i=1}^m\alpha_i^j\phi(x_i)^T\phi(x)=\sum_{i=1}^m\alpha_i^j\kappa(x_i,x)$



## 流形学习

### 等度量学习（Isomap)

将计算两点之间测地线距离的问题转化为计算近邻连接图上两点之间的最短路径问题。

在近邻连接图上计算亮点间的最短路径，可采用著名的	Dijkstra或Floyd算法，在得到任意两点的距离后，就可通过MDS来获得样本点在低维空间中的坐标

![image-20210804144957029](http://tenjoutena.oss-cn-guangzhou.aliyuncs.com/img/image-20210804144957029.png)

Isomap仅是得到了训练样本在地位空间的坐标，对于新样本，将训练样本的高维空间坐标作为输入、低维空间坐标作为输出，训练一个回归学习器来对新样本的地位空间坐标进行预测

#### 近邻图的构建

1.   k近邻图

指定近邻点个数

2.   $\epsilon$近邻图

指定距离阈值$\epsilon$，距离小于$\epsilon$的点被人为是近邻点

### 局部线性嵌入（LLE）

LLE试图保持领域内样本之间的线性关系

LLE先为每个样本$x_i$找到其近邻下标集合$Q_{ij}$，然后计算出基于$Q_i$中的样本点对$x_i$进心线性重构的系数$\omega_i$

![image-20210804152338307](http://tenjoutena.oss-cn-guangzhou.aliyuncs.com/img/image-20210804152338307.png)

LLE在地位空间中保持$\omega_i$不变，于是$x_i$对应的地位空间坐标$z_i$可通过下式求解

![image-20210804152448746](http://tenjoutena.oss-cn-guangzhou.aliyuncs.com/img/image-20210804152448746.png)

![image-20210804151835990](http://tenjoutena.oss-cn-guangzhou.aliyuncs.com/img/image-20210804151835990.png)



## 量度学习

事实上，每个空间对应了在样本属性上定义的一个距离亮度，而寻找合适的空间，实质上就是在寻找一个合适的距离度量。

对两个d维样本$x_i,x_j$，它们之间的平方欧式距离可写为

![image-20210804154935810](http://tenjoutena.oss-cn-guangzhou.aliyuncs.com/img/image-20210804154935810.png)

可以引入权重

![image-20210804155004340](http://tenjoutena.oss-cn-guangzhou.aliyuncs.com/img/image-20210804155004340.png)

将W替换称一个平台半正定对称矩阵M，于是得到马氏距离

![image-20210804155202274](http://tenjoutena.oss-cn-guangzhou.aliyuncs.com/img/image-20210804155202274.png)

M亦称度量矩阵

### NCA近邻成分分析

![image-20210804155837352](http://tenjoutena.oss-cn-guangzhou.aliyuncs.com/img/image-20210804155837352.png)

![image-20210804155908378]() 
